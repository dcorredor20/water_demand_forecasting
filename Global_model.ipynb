{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Global_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcorredor20/water_demand_forecasting/blob/main/Global_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekW44SxadeCw",
        "outputId": "7ef49c3a-027e-4f39-fcd4-884040e1e0c3"
      },
      "source": [
        "!pip install git+https://github.com/dcorredor20/water_demand_forecasting.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/dcorredor20/water_demand_forecasting.git\n",
            "  Cloning https://github.com/dcorredor20/water_demand_forecasting.git to /tmp/pip-req-build-898tphd_\n",
            "  Running command git clone -q https://github.com/dcorredor20/water_demand_forecasting.git /tmp/pip-req-build-898tphd_\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyyaml<6.0.0,>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from water-demand-forecasting==0.0.1) (5.4.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from water-demand-forecasting==0.0.1) (1.19.5)\n",
            "Requirement already satisfied: sklearn<0.1,>=0.0 in /usr/local/lib/python3.7/dist-packages (from water-demand-forecasting==0.0.1) (0.0)\n",
            "Requirement already satisfied: click<8.0.0,>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from water-demand-forecasting==0.0.1) (7.1.2)\n",
            "Requirement already satisfied: lint<2.0.0,>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from water-demand-forecasting==0.0.1) (1.2.1)\n",
            "Requirement already satisfied: matplotlib==3.1.3 in /usr/local/lib/python3.7/dist-packages (from water-demand-forecasting==0.0.1) (3.1.3)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from water-demand-forecasting==0.0.1) (1.1.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->water-demand-forecasting==0.0.1) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->water-demand-forecasting==0.0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->water-demand-forecasting==0.0.1) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->water-demand-forecasting==0.0.1) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib==3.1.3->water-demand-forecasting==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.7/dist-packages (from lint<2.0.0,>=1.2.1->water-demand-forecasting==0.0.1) (3.1.18)\n",
            "Requirement already satisfied: pylint in /usr/local/lib/python3.7/dist-packages (from lint<2.0.0,>=1.2.1->water-demand-forecasting==0.0.1) (2.9.6)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->water-demand-forecasting==0.0.1) (2018.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn<0.1,>=0.0->water-demand-forecasting==0.0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from gitpython->lint<2.0.0,>=1.2.1->water-demand-forecasting==0.0.1) (3.7.4.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython->lint<2.0.0,>=1.2.1->water-demand-forecasting==0.0.1) (4.0.7)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython->lint<2.0.0,>=1.2.1->water-demand-forecasting==0.0.1) (4.0.0)\n",
            "Requirement already satisfied: mccabe<0.7,>=0.6 in /usr/local/lib/python3.7/dist-packages (from pylint->lint<2.0.0,>=1.2.1->water-demand-forecasting==0.0.1) (0.6.1)\n",
            "Requirement already satisfied: astroid<2.7,>=2.6.5 in /usr/local/lib/python3.7/dist-packages (from pylint->lint<2.0.0,>=1.2.1->water-demand-forecasting==0.0.1) (2.6.6)\n",
            "Requirement already satisfied: isort<6,>=4.2.5 in /usr/local/lib/python3.7/dist-packages (from pylint->lint<2.0.0,>=1.2.1->water-demand-forecasting==0.0.1) (5.9.3)\n",
            "Requirement already satisfied: toml>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pylint->lint<2.0.0,>=1.2.1->water-demand-forecasting==0.0.1) (0.10.2)\n",
            "Requirement already satisfied: setuptools>=20.0 in /usr/local/lib/python3.7/dist-packages (from astroid<2.7,>=2.6.5->pylint->lint<2.0.0,>=1.2.1->water-demand-forecasting==0.0.1) (57.2.0)\n",
            "Requirement already satisfied: typed-ast<1.5,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from astroid<2.7,>=2.6.5->pylint->lint<2.0.0,>=1.2.1->water-demand-forecasting==0.0.1) (1.4.3)\n",
            "Requirement already satisfied: wrapt<1.13,>=1.11 in /usr/local/lib/python3.7/dist-packages (from astroid<2.7,>=2.6.5->pylint->lint<2.0.0,>=1.2.1->water-demand-forecasting==0.0.1) (1.12.1)\n",
            "Requirement already satisfied: lazy-object-proxy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from astroid<2.7,>=2.6.5->pylint->lint<2.0.0,>=1.2.1->water-demand-forecasting==0.0.1) (1.6.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn<0.1,>=0.0->water-demand-forecasting==0.0.1) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn<0.1,>=0.0->water-demand-forecasting==0.0.1) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anl9-w36hmoc",
        "outputId": "dafb359a-e2f2-4dd1-81f2-c4246f542182"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "!ls gdrive "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwsONc8ddeFE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from water_demand_forecasting import custom_plots\n",
        "from water_demand_forecasting.wdf_model import WDF_Model\n",
        "import tensorflow\n",
        "import time\n",
        "from tensorflow.keras.layers import Input, Dense, SimpleRNN, GRU, LSTM, Flatten, Dropout, Conv1D, Concatenate,BatchNormalization, ReLU, Add, ZeroPadding1D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import *\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHajDC4Ad0My"
      },
      "source": [
        "# variables_model\n",
        "VARIABLES = [\"case_study\", \"days\"]\n",
        "T = 168"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfLWYM-Recf2"
      },
      "source": [
        "case_studies = dict()\n",
        "case_studies[2] = {'train':'/content/gdrive/MyDrive/DataThesis/DATI/Ferrara/Qh_CS2_14.txt',\n",
        "                   'test':'/content/gdrive/MyDrive/DataThesis/DATI/Ferrara/Qh_CS2_15.txt'}\n",
        "case_studies[3] = {'train':'/content/gdrive/MyDrive/DataThesis/DATI/Ferrara/Qh_CS3_14.txt',\n",
        "                   'test':'/content/gdrive/MyDrive/DataThesis/DATI/Ferrara/Qh_CS3_15.txt'}\n",
        "case_studies[4] = {'train':'/content/gdrive/MyDrive/DataThesis/DATI/Ferrara/Qh_CS4_14.txt',\n",
        "                   'test':'/content/gdrive/MyDrive/DataThesis/DATI/Ferrara/Qh_CS4_15.txt'}\n",
        "case_studies[5] = {'train':'/content/gdrive/MyDrive/DataThesis/DATI/Ferrara/Qh_CS5_14.txt',\n",
        "                   'test':'/content/gdrive/MyDrive/DataThesis/DATI/Ferrara/Qh_CS5_15.txt'}\n",
        "case_studies[6] = {'train':'/content/gdrive/MyDrive/DataThesis/DATI/Ferrara/Qh_CS6_14.txt',\n",
        "                   'test':'/content/gdrive/MyDrive/DataThesis/DATI/Ferrara/Qh_CS6_15.txt'}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ4BQch7deI7"
      },
      "source": [
        "for c in case_studies.keys():\n",
        "  config_temp = dict()\n",
        "  config_temp['case_study'] = dict()\n",
        "  config_temp['days'] = dict()\n",
        "  config_temp['case_study']['train'] = case_studies[c]['train']\n",
        "  config_temp['case_study']['test'] = case_studies[c]['test']\n",
        "  config_temp['days'] = {\"train\": 'gdrive/MyDrive/DataThesis/Meteo/days2014.csv',\n",
        "      \"test\": 'gdrive/MyDrive/DataThesis/Meteo/days2015.csv'}\n",
        "  Xtra, Ytra, Xval, Yval, Xtest, Ytest, scx, scy = WDF_Model.data_preprocessing(\n",
        "      VARIABLES, config_temp, lookback=T, type_scaler = \"Standard\"\n",
        "  )\n",
        "  case_studies[c]['Xtra'] = Xtra\n",
        "  case_studies[c]['Ytra'] = Ytra\n",
        "  case_studies[c]['Xval'] = Xval\n",
        "  case_studies[c]['Yval'] = Yval\n",
        "  case_studies[c]['Xtest'] = Xtest\n",
        "  case_studies[c]['Ytest'] = Ytest\n",
        "  case_studies[c]['scx'] = scx\n",
        "  case_studies[c]['scy'] = scy\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3IUjhK9iRWO"
      },
      "source": [
        "Xtra = np.concatenate([case_studies[c]['Xtra'] for c in case_studies.keys()])\n",
        "Xval = np.concatenate([case_studies[c]['Xval'] for c in case_studies.keys()])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra3mxyBMjR0l"
      },
      "source": [
        "Ytra = np.concatenate([case_studies[c]['Ytra'] for c in case_studies.keys()])\n",
        "Yval = np.concatenate([case_studies[c]['Yval'] for c in case_studies.keys()])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbYehL6jjBOe"
      },
      "source": [
        "# callbacks: early stopping and Model checkpoint\n",
        "earlyStopping= EarlyStopping(monitor='val_loss', patience=10, min_delta=1e-4, mode='auto')\n",
        "mcp_save = ModelCheckpoint('model_weightsdil.hdf5', save_best_only=True, monitor='val_loss', mode='auto', save_weights_only=True)\n",
        "lr_reduced = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=0, min_delta=1e-3, mode='auto')\n",
        "callbacks = [earlyStopping, mcp_save, lr_reduced]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTlOglKRjjRz"
      },
      "source": [
        "dilation_rates = (2**exp for exp in range(0, 5))\n",
        "filter_size_block = 2\n",
        "filter_size_branch = 1\n",
        "number_filters = 32\n",
        "dropout_rate = 0.2\n",
        "outputs = 24\n",
        "loss = 'mae'\n",
        "metrics = 'mse'\n",
        "epochs = 500\n",
        "batch_size = 32"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Re_hbUSyjg0",
        "outputId": "375a8c77-620c-42ac-8e19-fe7e4a203806"
      },
      "source": [
        "i = Input(shape=(T,len(VARIABLES)), name='Input layer')\n",
        "\n",
        "x01 = ZeroPadding1D(padding=(filter_size_block-1,0))(i)\n",
        "\n",
        "concatenated = x01\n",
        "for d in dilation_rates:\n",
        "  x1 = Conv1D(filters=number_filters, kernel_size=(filter_size_branch))(concatenated)\n",
        "\n",
        "  x2 = Conv1D(number_filters, kernel_size=(filter_size_block), padding='causal', dilation_rate=d)(concatenated)\n",
        "  x2 = BatchNormalization()(x2)\n",
        "  x2 = ReLU()(x2)\n",
        "  x2 = Dropout(rate=dropout_rate, seed=1234)(x2)\n",
        "  concatenated = Add()([x2, x1])\n",
        "   \n",
        "x = Flatten()(concatenated)\n",
        "\n",
        "x = Dense(units=outputs, activation='linear', name='Output')(x)\n",
        "\n",
        "model = Model(i, x)\n",
        "print(model.summary())\n",
        "\n",
        "# compile the model\n",
        "optimizer = Adam(learning_rate = 0.0005)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metrics])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input layer (InputLayer)        [(None, 168, 2)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding1d (ZeroPadding1D)  (None, 169, 2)       0           Input layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 169, 32)      160         zero_padding1d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 169, 32)      128         conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu (ReLU)                    (None, 169, 32)      0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 169, 32)      0           re_lu[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 169, 32)      96          zero_padding1d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 169, 32)      0           dropout[0][0]                    \n",
            "                                                                 conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 169, 32)      2080        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 169, 32)      128         conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_1 (ReLU)                  (None, 169, 32)      0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 169, 32)      0           re_lu_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 169, 32)      1056        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 169, 32)      0           dropout_1[0][0]                  \n",
            "                                                                 conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 169, 32)      2080        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 169, 32)      128         conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_2 (ReLU)                  (None, 169, 32)      0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 169, 32)      0           re_lu_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 169, 32)      1056        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 169, 32)      0           dropout_2[0][0]                  \n",
            "                                                                 conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 169, 32)      2080        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 169, 32)      128         conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_3 (ReLU)                  (None, 169, 32)      0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 169, 32)      0           re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 169, 32)      1056        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 169, 32)      0           dropout_3[0][0]                  \n",
            "                                                                 conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 169, 32)      2080        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 169, 32)      128         conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_4 (ReLU)                  (None, 169, 32)      0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 169, 32)      0           re_lu_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 169, 32)      1056        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 169, 32)      0           dropout_4[0][0]                  \n",
            "                                                                 conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 5408)         0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Output (Dense)                  (None, 24)           129816      flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 143,256\n",
            "Trainable params: 142,936\n",
            "Non-trainable params: 320\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk6qkKGpynNJ",
        "outputId": "949634ab-7280-4d63-9e14-7a22d231c0bf"
      },
      "source": [
        "start = time.time()\n",
        "r = model.fit(Xtra, Ytra, verbose = 1, validation_data=(Xval, Yval), epochs=epochs, callbacks=callbacks, batch_size=batch_size)\n",
        "end = time.time()\n",
        "print('Total training time: ', end-start)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "1005/1005 [==============================] - 45s 11ms/step - loss: 0.4383 - mse: 0.4408 - val_loss: 0.1514 - val_mse: 0.0428\n",
            "Epoch 2/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.1693 - mse: 0.0522 - val_loss: 0.1371 - val_mse: 0.0375\n",
            "Epoch 3/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1434 - mse: 0.0400 - val_loss: 0.1298 - val_mse: 0.0334\n",
            "Epoch 4/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1339 - mse: 0.0361 - val_loss: 0.1204 - val_mse: 0.0312\n",
            "Epoch 5/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1290 - mse: 0.0343 - val_loss: 0.1225 - val_mse: 0.0312\n",
            "Epoch 6/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1257 - mse: 0.0331 - val_loss: 0.1176 - val_mse: 0.0297\n",
            "Epoch 7/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1227 - mse: 0.0319 - val_loss: 0.1171 - val_mse: 0.0300\n",
            "Epoch 8/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.1206 - mse: 0.0311 - val_loss: 0.1150 - val_mse: 0.0284\n",
            "Epoch 9/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1188 - mse: 0.0305 - val_loss: 0.1218 - val_mse: 0.0308\n",
            "Epoch 10/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1172 - mse: 0.0298 - val_loss: 0.1120 - val_mse: 0.0275\n",
            "Epoch 11/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.1162 - mse: 0.0294 - val_loss: 0.1116 - val_mse: 0.0273\n",
            "Epoch 12/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1145 - mse: 0.0288 - val_loss: 0.1128 - val_mse: 0.0277\n",
            "Epoch 13/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1138 - mse: 0.0286 - val_loss: 0.1130 - val_mse: 0.0277\n",
            "Epoch 14/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1131 - mse: 0.0282 - val_loss: 0.1127 - val_mse: 0.0271\n",
            "Epoch 15/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1121 - mse: 0.0279 - val_loss: 0.1121 - val_mse: 0.0270\n",
            "Epoch 16/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1079 - mse: 0.0266 - val_loss: 0.1054 - val_mse: 0.0254\n",
            "Epoch 17/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.1072 - mse: 0.0264 - val_loss: 0.1046 - val_mse: 0.0250\n",
            "Epoch 18/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.1067 - mse: 0.0262 - val_loss: 0.1050 - val_mse: 0.0251\n",
            "Epoch 19/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1063 - mse: 0.0260 - val_loss: 0.1051 - val_mse: 0.0252\n",
            "Epoch 20/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1060 - mse: 0.0259 - val_loss: 0.1043 - val_mse: 0.0249\n",
            "Epoch 21/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1058 - mse: 0.0258 - val_loss: 0.1043 - val_mse: 0.0245\n",
            "Epoch 22/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1054 - mse: 0.0257 - val_loss: 0.1035 - val_mse: 0.0244\n",
            "Epoch 23/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1052 - mse: 0.0255 - val_loss: 0.1035 - val_mse: 0.0245\n",
            "Epoch 24/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.1049 - mse: 0.0254 - val_loss: 0.1031 - val_mse: 0.0244\n",
            "Epoch 25/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1045 - mse: 0.0253 - val_loss: 0.1036 - val_mse: 0.0243\n",
            "Epoch 26/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1042 - mse: 0.0252 - val_loss: 0.1026 - val_mse: 0.0242\n",
            "Epoch 27/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1041 - mse: 0.0251 - val_loss: 0.1032 - val_mse: 0.0245\n",
            "Epoch 28/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1038 - mse: 0.0250 - val_loss: 0.1024 - val_mse: 0.0240\n",
            "Epoch 29/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1036 - mse: 0.0249 - val_loss: 0.1030 - val_mse: 0.0241\n",
            "Epoch 30/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.1015 - mse: 0.0243 - val_loss: 0.1006 - val_mse: 0.0235\n",
            "Epoch 31/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.1012 - mse: 0.0242 - val_loss: 0.0999 - val_mse: 0.0233\n",
            "Epoch 32/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1010 - mse: 0.0241 - val_loss: 0.0999 - val_mse: 0.0232\n",
            "Epoch 33/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1009 - mse: 0.0240 - val_loss: 0.0998 - val_mse: 0.0233\n",
            "Epoch 34/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1007 - mse: 0.0240 - val_loss: 0.0993 - val_mse: 0.0231\n",
            "Epoch 35/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1004 - mse: 0.0239 - val_loss: 0.1001 - val_mse: 0.0233\n",
            "Epoch 36/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.1005 - mse: 0.0239 - val_loss: 0.0998 - val_mse: 0.0232\n",
            "Epoch 37/500\n",
            "1005/1005 [==============================] - 11s 10ms/step - loss: 0.1001 - mse: 0.0238 - val_loss: 0.0994 - val_mse: 0.0231\n",
            "Epoch 38/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1001 - mse: 0.0237 - val_loss: 0.0995 - val_mse: 0.0230\n",
            "Epoch 39/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.1002 - mse: 0.0238 - val_loss: 0.1001 - val_mse: 0.0231\n",
            "Epoch 40/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0989 - mse: 0.0234 - val_loss: 0.0981 - val_mse: 0.0227\n",
            "Epoch 41/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0988 - mse: 0.0234 - val_loss: 0.0980 - val_mse: 0.0227\n",
            "Epoch 42/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0986 - mse: 0.0233 - val_loss: 0.0986 - val_mse: 0.0227\n",
            "Epoch 43/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.0985 - mse: 0.0233 - val_loss: 0.0987 - val_mse: 0.0228\n",
            "Epoch 44/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.0984 - mse: 0.0232 - val_loss: 0.0984 - val_mse: 0.0227\n",
            "Epoch 45/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0985 - mse: 0.0232 - val_loss: 0.0979 - val_mse: 0.0226\n",
            "Epoch 46/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.0978 - mse: 0.0230 - val_loss: 0.0975 - val_mse: 0.0225\n",
            "Epoch 47/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.0977 - mse: 0.0230 - val_loss: 0.0975 - val_mse: 0.0225\n",
            "Epoch 48/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.0976 - mse: 0.0230 - val_loss: 0.0974 - val_mse: 0.0224\n",
            "Epoch 49/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0976 - mse: 0.0230 - val_loss: 0.0974 - val_mse: 0.0225\n",
            "Epoch 50/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0975 - mse: 0.0229 - val_loss: 0.0973 - val_mse: 0.0224\n",
            "Epoch 51/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0972 - mse: 0.0229 - val_loss: 0.0972 - val_mse: 0.0224\n",
            "Epoch 52/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0972 - mse: 0.0229 - val_loss: 0.0972 - val_mse: 0.0224\n",
            "Epoch 53/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0971 - mse: 0.0228 - val_loss: 0.0971 - val_mse: 0.0224\n",
            "Epoch 54/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0972 - mse: 0.0228 - val_loss: 0.0971 - val_mse: 0.0224\n",
            "Epoch 55/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0972 - mse: 0.0229 - val_loss: 0.0971 - val_mse: 0.0223\n",
            "Epoch 56/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0971 - mse: 0.0228 - val_loss: 0.0971 - val_mse: 0.0223\n",
            "Epoch 57/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0971 - mse: 0.0228 - val_loss: 0.0972 - val_mse: 0.0223\n",
            "Epoch 58/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0971 - mse: 0.0228 - val_loss: 0.0970 - val_mse: 0.0223\n",
            "Epoch 59/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.0971 - mse: 0.0228 - val_loss: 0.0970 - val_mse: 0.0223\n",
            "Epoch 60/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.0970 - mse: 0.0228 - val_loss: 0.0970 - val_mse: 0.0223\n",
            "Epoch 61/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0969 - mse: 0.0227 - val_loss: 0.0969 - val_mse: 0.0223\n",
            "Epoch 62/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0969 - mse: 0.0227 - val_loss: 0.0969 - val_mse: 0.0223\n",
            "Epoch 63/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0968 - mse: 0.0227 - val_loss: 0.0970 - val_mse: 0.0223\n",
            "Epoch 64/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0968 - mse: 0.0227 - val_loss: 0.0969 - val_mse: 0.0223\n",
            "Epoch 65/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.0966 - mse: 0.0227 - val_loss: 0.0969 - val_mse: 0.0223\n",
            "Epoch 66/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.0968 - mse: 0.0227 - val_loss: 0.0969 - val_mse: 0.0223\n",
            "Epoch 67/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0967 - mse: 0.0227 - val_loss: 0.0969 - val_mse: 0.0223\n",
            "Epoch 68/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0967 - mse: 0.0227 - val_loss: 0.0968 - val_mse: 0.0223\n",
            "Epoch 69/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0968 - mse: 0.0227 - val_loss: 0.0968 - val_mse: 0.0223\n",
            "Epoch 70/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0967 - mse: 0.0227 - val_loss: 0.0968 - val_mse: 0.0222\n",
            "Epoch 71/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.0967 - mse: 0.0227 - val_loss: 0.0968 - val_mse: 0.0222\n",
            "Epoch 72/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.0966 - mse: 0.0227 - val_loss: 0.0968 - val_mse: 0.0223\n",
            "Epoch 73/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.0967 - mse: 0.0227 - val_loss: 0.0968 - val_mse: 0.0222\n",
            "Epoch 74/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0967 - mse: 0.0227 - val_loss: 0.0968 - val_mse: 0.0223\n",
            "Epoch 75/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.0967 - mse: 0.0227 - val_loss: 0.0968 - val_mse: 0.0223\n",
            "Epoch 76/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.0967 - mse: 0.0227 - val_loss: 0.0968 - val_mse: 0.0223\n",
            "Epoch 77/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0966 - mse: 0.0227 - val_loss: 0.0968 - val_mse: 0.0222\n",
            "Epoch 78/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0966 - mse: 0.0226 - val_loss: 0.0968 - val_mse: 0.0222\n",
            "Epoch 79/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0966 - mse: 0.0227 - val_loss: 0.0968 - val_mse: 0.0223\n",
            "Epoch 80/500\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0966 - mse: 0.0227 - val_loss: 0.0968 - val_mse: 0.0223\n",
            "Epoch 81/500\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.0967 - mse: 0.0227 - val_loss: 0.0968 - val_mse: 0.0222\n",
            "Total training time:  870.3103966712952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuVzZXpnlZuA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "dc6e7379-6037-47e1-b2d8-4b8042678ce3"
      },
      "source": [
        "custom_plots.loss_plot(r, 'GlobalModel', color = 'r')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipQAs7CploGQ"
      },
      "source": [
        "model.load_weights('model_weightsdil.hdf5')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LcawFsC1dph"
      },
      "source": [
        "def print_metrics(y,ypred,dataset, scy):\n",
        "  y = scy.inverse_transform(y)\n",
        "  ypred = scy.inverse_transform(ypred)\n",
        "  print(f'{dataset}\\t\\tRMSE:{mean_squared_error(y,ypred)**0.5:.3f}\\tMAE:{mean_absolute_error(y,ypred):.3f}\\tR2:{r2_score(y,ypred):.3f}')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crMCi8WR1zJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57de76b0-6a35-4e05-f58c-ece4e7365a43"
      },
      "source": [
        "for c in case_studies.keys():\n",
        "  print(f'Test for CS{c}')\n",
        "  print_metrics(case_studies[c]['Ytest'].reshape(-1,1),model.predict(case_studies[c]['Xtest']).reshape(-1,1),'Test',case_studies[c]['scy'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test for CS2\n",
            "Test\t\tRMSE:41.082\tMAE:29.490\tR2:0.954\n",
            "Test for CS3\n",
            "Test\t\tRMSE:4.615\tMAE:3.151\tR2:0.969\n",
            "Test for CS4\n",
            "Test\t\tRMSE:1.229\tMAE:0.794\tR2:0.979\n",
            "Test for CS5\n",
            "Test\t\tRMSE:2.504\tMAE:1.627\tR2:0.951\n",
            "Test for CS6\n",
            "Test\t\tRMSE:6.404\tMAE:4.293\tR2:0.980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FswVwpZP9J8l",
        "outputId": "6ea94501-00d5-42d0-b777-65ceca9caaea"
      },
      "source": [
        "for c in case_studies.keys():\n",
        "  for y in [1,2]:\n",
        "    mode = 'val' if y == 1 else 'test'\n",
        "    Y_hat = model.predict(case_studies[c][f'X{mode}'])\n",
        "    Y_test = case_studies[c]['scy'].inverse_transform(case_studies[c][f'Y{mode}'])\n",
        "    Yhat = case_studies[c]['scy'].inverse_transform(Y_hat)\n",
        "    dat1y2 = pd.DataFrame(Y_test)\n",
        "    dat2y2 = pd.DataFrame(Yhat)\n",
        "    e = 100*np.sum(np.abs((dat1y2 - dat2y2)/np.mean(dat1y2, axis = 0)), axis = 0)/len(dat1y2)\n",
        "    print(f'MAE CS{c} Year {y} = {e.mean()}')\n",
        "  print('-'*10)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE CS2 Year 1 = 2.1898838570199994\n",
            "MAE CS2 Year 2 = 3.0492126490379428\n",
            "----------\n",
            "MAE CS3 Year 1 = 2.8028393034865453\n",
            "MAE CS3 Year 2 = 3.2840456840994374\n",
            "----------\n",
            "MAE CS4 Year 1 = 2.989449327124058\n",
            "MAE CS4 Year 2 = 3.215735261684264\n",
            "----------\n",
            "MAE CS5 Year 1 = 2.5612284820465874\n",
            "MAE CS5 Year 2 = 2.866633070899496\n",
            "----------\n",
            "MAE CS6 Year 1 = 2.161666396989536\n",
            "MAE CS6 Year 2 = 2.419545151353662\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN56-NM3PyHi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}